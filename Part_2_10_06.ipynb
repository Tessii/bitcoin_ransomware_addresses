{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AhvWqxRME6q"
   },
   "source": [
    "<center><h1>Bitcoin</h1></center>\n",
    "<center>CDASO2020U \"Data Mining, Machine Learning and Deep Learning\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Structure</h1></center>\n",
    "\n",
    "A. [Exploratory data analysis](#A)\n",
    "\n",
    "B. [Pre-processing](#B)\n",
    "\n",
    "C. [Supervised Machine Learning](#C)\n",
    "1. [Data set plit](#1)\n",
    "2. [Decision Tree](#2)\n",
    "3. [Random Forest](#3)\n",
    "4. [Logistic Regression](#4)\n",
    "5. [SVM](5)\n",
    "6. [KNN](#6)\n",
    "7. [Voting Classifier](#7)\n",
    "7. [Neural Newtworks](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/theresawohlsen/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras as keras\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "import lime #conda install -c conda-forge lime\n",
    "import lime.lime_tabular\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "from plotly import graph_objs as go  #!conda install --yes --prefix {sys.prefix} plotly (for windows users who's cmd sucks)\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import pydotplus\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score, confusion_matrix, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz, DecisionTreeClassifier\n",
    "from time import process_time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Exploratory data analysis <a class=\"anchor\" id=\"A\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhOKs5k0ME7K"
   },
   "source": [
    "# B. Pre-processing  <a class=\"anchor\" id=\"B\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dataframes and drop index column\n",
    "df = pd.read_csv('df.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df_scaled = pd.read_csv('df_scaled.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df_ransomware = pd.read_csv('df_ransomware.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df_ransomware_scaled = pd.read_csv('df_ransomware_scaled.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhOKs5k0ME7K"
   },
   "source": [
    "# C. Supervised Machine Learning  <a class=\"anchor\" id=\"C\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data set split  <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare test set for ransomware families detection\n",
    "def prepare_test_sets(df):\n",
    "    # select relevant features\n",
    "    features = ['length', 'weight', 'count', 'looped',\n",
    "       'neighbors', 'income', 'repeated', 'repeated_counter']\n",
    "    X = df[features]\n",
    "    y = df['label']\n",
    "\n",
    "    #Perform train/test split.\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, y)\n",
    "    \n",
    "    return xTrain, xTest, yTrain, yTest, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare test set for ransomware detection in general\n",
    "def prepare_test_sets_all(df):\n",
    "    # select relevant features\n",
    "    features = ['length', 'weight', 'count', 'looped',\n",
    "       'neighbors', 'income', 'repeated', 'repeated_counter' ]\n",
    "    X = df[features]\n",
    "    y = df['binary_label']\n",
    "\n",
    "    #Perform train/test split.\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(X, y)\n",
    "    \n",
    "    return xTrain, xTest, yTrain, yTest, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll = prepare_test_sets_all(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree  <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function logic for Decision Tree\n",
    "def get_decision_tree(x1, x2, y1, y2, features):\n",
    "    class_tree = DecisionTreeClassifier(max_depth = 3)\n",
    "    class_tree.fit(x1, y1)\n",
    "    \n",
    "    yPred_tree = class_tree.predict(x2)\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"Accuracy Score : \", metrics.accuracy_score(y2, yPred_tree))\n",
    "    print(\"Precision Score : \", metrics.precision_score(y2, yPred_tree, average = None))\n",
    "    print(\"Recall Score : \", metrics.recall_score(y2, yPred_tree, average = None))\n",
    "    print(\"F1 Score : \", metrics.f1_score(y2, yPred_tree, average = None))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print('Confusion Matrix : \\n', confusion_matrix(y2, yPred_tree))\n",
    "    \n",
    "    # get feature importances\n",
    "    featureImportances = list(zip(features, class_tree.feature_importances_))\n",
    "    print(list(sorted(featureImportances, key = lambda k: k[1], reverse = True)))\n",
    "    \n",
    "    # visualize tree\n",
    "    if False:\n",
    "        dot_data = StringIO()\n",
    "\n",
    "        export_graphviz(\n",
    "            reg,\n",
    "            out_file= dot_data,\n",
    "            feature_names=features,\n",
    "            rounded=True,\n",
    "            filled=True\n",
    "        )\n",
    "\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "        Image(graph.create_png())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2.1 Decision Tree for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_decision_tree(xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Decision Tree for ransomware dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_decision_tree(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_random_forest(x1, x2, y1, y2, features, gs = True):\n",
    "    # train the model\n",
    "    if gs:\n",
    "        rf = RandomForestClassifier()\n",
    "    else:\n",
    "        rf = RandomForestClassifier(bootstrap = True, max_depth = 100, max_features = 3,\n",
    "                                    min_samples_leaf = 3, min_samples_split = 10, n_estimators = 800)\n",
    "    rf.fit(x1, y1)\n",
    "    \n",
    "    yPredRf = rf.predict(x2)\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"Classfication report : \", metrics.classification_report(y2, yPredRf))\n",
    "    #print(\"Accuracy Score : \", metrics.accuracy_score(y2, yPredRf))\n",
    "    #print(\"Precision Score : \", metrics.precision_score(y2, yPredRf, average = None))\n",
    "    #print(\"Recall Score : \", metrics.recall_score(y2, yPredRf, average = None))\n",
    "    #print(\"F1 Score : \", metrics.f1_score(y2, yPredRf, average = None))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix : \\n\", confusion_matrix(y2, yPredRf))\n",
    "    \n",
    "    # feature importances\n",
    "    featureImportances = list(zip(features, rf.feature_importances_))\n",
    "    print(list(sorted(featureImportances, key = lambda k: k[1], reverse = True)))\n",
    "    \n",
    "    # Take a look at some results\n",
    "    rf_results = pd.DataFrame({'Actual' : y2, 'Predicted' : yPredRf})\n",
    "    print(rf_results.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forest for Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_random_forest(xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Random Forest for Ransomware Dataset (added the hyperparameters that were identified with GS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Take a look at families of ransomware distribution in order to compare with metrics\n",
    "df_ransomware_scaled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_random_forest(xTrain, xTest, yTrain, yTest, features, gs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"green\">This is the best result we have so far: 0.83, which was obtained by using the hyperparameters identified with Grid Search. \n",
    "\n",
    "NOTE: INstead of outputing all the scores individually, I found out you can use - meitrcs.classificatoin_report and its going to show you the whole report on the scores. Also it does some weighted averages for all the classes. \n",
    "\n",
    "Read more here: https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1</font>\n",
    "\n",
    "Also --> When you look at where you have 0.0 and at the value_counts() output from above, you can see that we got bad results for families with few instances. The most populated families actually have better results.\n",
    "\n",
    "\n",
    "#### REPORT NOTE: It would be more difficult to identify new families of ransomware, because we can see already that less populated classes get bad results. Thus, identification of existing families would only be possible most of the times. In spite of this, we have the binary classification which gives quite good results - meaning that we would be able to use the algorithm just for the detection of ransomware (and not for tha families yet, if its a new one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest for Ransomware Dataset with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function logif for Random Forest with Grid Search\n",
    "def get_random_forest_gs(x1, x2, y1, y2, features):\n",
    "    # train the model\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    # Parameters for Grid Search\n",
    "    params = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [80, 100],\n",
    "        'max_features': [2, 3],\n",
    "        'min_samples_leaf': [3, 4],\n",
    "        'min_samples_split': [8, 10],\n",
    "        'n_estimators': [100, 800]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = params, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "    \n",
    "    grid_search.fit(x1, y1)\n",
    "    \n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_random_forest_gs(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\">With the existing list of parameters got the following best score:\n",
    "'bootstrap': True, 'max_depth': 100, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 10, 'n_estimators': 800\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function Logic for Logistic Regression\n",
    "\n",
    "def get_logistic_regression(x1, x2, y1, y2, features, gs = True):\n",
    "    # Added execution time for the training set\n",
    "    t1_start = process_time()\n",
    "    if gs:\n",
    "        log_regressor = LogisticRegression()\n",
    "    else:\n",
    "        log_regressor = LogisticRegression(C = 3, penalty = \"l1\")\n",
    "            \n",
    "    log_regressor.fit(x1, y1)\n",
    "    t1_stop = process_time()\n",
    "    print(\"Total time for the training set:\", t1_stop-t1_start)\n",
    "    \n",
    "    yPredLog = log_regressor.predict(x2)\n",
    "    yPredLog\n",
    "    \n",
    "    print(\"Score Report : \", metrics.classification_report(y2, yPredLog))\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"Accuracy : \", metrics.accuracy_score(y2, yPredLog))\n",
    "    print(\"Precision : \", metrics.precision_score(y2, yPredLog, average = None))\n",
    "    print(\"Recall : \", metrics.recall_score(y2, yPredLog, average = None))\n",
    "    \n",
    "    log_results = pd.DataFrame({'Actual' : y2, 'Predicted' : yPredLog})\n",
    "    print(log_results.head(25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Logistic Regression for Ransomware Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_logistic_regression(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\">\n",
    "Before this, I tried to do the logistic regression for the ransomware dataset on the unscaled one - the results were quire poor, and now since we scaled the data I actually see that the results got better, without any parameter tunning.\n",
    "    \n",
    "Time : 4.234375\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Logistic Regression for Ransomware Dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logic Function for Logistic Regression with PCA\n",
    "\n",
    "def get_logistic_regression_pca(x1, x2, y1, y2, features):\n",
    "    \n",
    "    # Initialize PCA\n",
    "    pca_log = PCA(n_components = 0.95)\n",
    "    pca_log.fit(x1)\n",
    "    \n",
    "    train_pca = pca_log.transform(x1)\n",
    "    test_pca = pca_log.transform(x2)\n",
    "    \n",
    "    # Execution time for the training set with PCA\n",
    "    t1_start = process_time()\n",
    "    log_regressor_pca = LogisticRegression().fit(train_pca, y1)\n",
    "    t1_stop = process_time()\n",
    "    print(\"Total time for the training set:\",t1_stop-t1_start)\n",
    "    \n",
    "    # Check the first results of the prediction\n",
    "    log_results_pca = pd.DataFrame({'Actual' : y2, 'Predicted' : log_regressor_pca.predict(test_pca)})\n",
    "    print(log_results_pca.head(25))\n",
    "    \n",
    "    print(\"Score Report : \", metrics.classification_report(y2, log_regressor_pca.predict(test_pca) ))\n",
    "    #print(\"Accuracy : \", metrics.accuracy_score(yTest,log_regressor_pca.predict(test_pca)))\n",
    "    #print(\"Precision : \", metrics.precision_score(yTest, log_regressor_pca.predict(test_pca), average = None))\n",
    "    #print(\"Recall : \", metrics.recall_score(yTest, log_regressor_pca.predict(test_pca), average = None))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_logistic_regression_pca(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\"> Much better speed on this ransomware dataset, but since the dataset was reduced with PCA, the results are much worse. And since we have good speed already with Logistic Regression, not much worth it to add PCA to it.\n",
    "\n",
    "Time : 1.4375\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Logistic Regression for Ransomware Dataset with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_logistic_regression_gs(x1, x2, y1, y2, features):\n",
    "    # Choose parameters for logistic regression\n",
    "    params = {\"C\" : [1, 2, 3], \"penalty\" : [\"l1\",\"l2\"]}\n",
    "    \n",
    "    log_regressor = LogisticRegression()\n",
    "    log_regressor_cv = GridSearchCV(log_regressor, params, cv=3)\n",
    "    log_regressor_cv.fit(x1, y1)\n",
    "    \n",
    "    # Get information on best parameters/score\n",
    "    print(\"Tuned hyperparameters : \", log_regressor_cv.best_params_)\n",
    "    print(\"Best Score : \", log_regressor_cv.best_score_)\n",
    "    \n",
    "    log_regressor_tuned = LogisticRegression(C = 3, penalty = \"l1\")\n",
    "    log_regressor_tuned.fit(x1, y1)\n",
    "    log_regressor_tuned.predict(x2)\n",
    "    print(\"Score : \", log_regressor_tuned.score(x2, y2))\n",
    "    \n",
    "    # Take a look at first results\n",
    "    log_results = pd.DataFrame({'Actual' : y2, 'Predicted' : log_regressor_tuned.predict(x2)})\n",
    "    print(log_results.head(25))\n",
    "    \n",
    "    print(\"Score Report : \", metrics.classification_report(y2, log_regressor_tuned.predict(x2)))\n",
    "    #print(\"Accuracy : \", metrics.accuracy_score(yTest, log_regressor_tuned.predict(xTest)))\n",
    "    #print(\"Precision : \", metrics.precision_score(yTest, log_regressor_tuned.predict(xTest), average = None))\n",
    "    #print(\"Recall : \", metrics.recall_score(yTest, log_regressor_tuned.predict(xTest), average = None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change False to use tunned hyperparameters\n",
    "get_logistic_regression(xTrain, xTest, yTrain, yTest, features, gs = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_logistic_regression_gs(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\">\n",
    "Tuned hyperparameters :  {'C': 3, 'penalty': 'l1'} - Best Parameters\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"purple\"> Slightly better results with Grid Search, going from 0.67 to 0.69 </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Logistic Regression for Entire Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll = prepare_test_sets_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_logistic_regression(xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"purple\">TO BE DONE: LR PCA for whole dataset to see the speed </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Logistic Regression for Entire Dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll = prepare_test_sets(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_logistic_regression_pca(xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SVM <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 SVM for Ransomware Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassifier(ktype):\n",
    "    if ktype == \"Polynomial\":\n",
    "        return SVC(kernel = 'poly', gamma = 'auto')\n",
    "    elif ktype == \"RBF\":\n",
    "        return SVC(kernel = 'rbf', gamma = \"auto\")\n",
    "    elif ktype == \"Sigmoid\":\n",
    "        return SVC(kernel = 'sigmoid', gamma = \"auto\")\n",
    "    elif ktype == \"Linear\":\n",
    "        return SVC(kernel = 'linear', gamma = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm(x1, x2, y1, y2, features, kernels):\n",
    "    for i in kernels:\n",
    "        svcClf = getClassifier(i)\n",
    "        svcClf.fit(xTrain, yTrain)\n",
    "        y_predSvm = svcClf.predict(xTest)\n",
    "    \n",
    "        print(str(i))\n",
    "        print(\"Accuracy Score : \", metrics.accuracy_score(yTest, y_predSvm))\n",
    "        #print(\"Precision Score : \", metrics.precision_score(yTest, y_predSvm, average = None))\n",
    "        #print(\"Recall Score : \", metrics.recall_score(yTest, y_predSvm, average = None))\n",
    "        #print(\"F1 Score : \", metrics.f1_score(yTest, y_predSvm, average = None))\n",
    "    \n",
    "        #Confusion Matrix\n",
    "        #print(\"Confusion Matrix : \\n\", metrics.confusion_matrix(yTest, y_predSvm))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernels for SVM\n",
    "kernels = ['Polynomial', 'Sigmoid', 'Linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    get_svm(xTrain, xTest, yTrain, yTest, features, kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\">This usually gives good results, but don't try to run it always - because it takes too much time to go thru all the kernels. Thats why I even deleted the RBF one, because that was the slowest. </font>\n",
    "\n",
    "<font color = \"purple\"> TO DO: PCA FOR SVM with rasnwaomre dataset </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 SVM for Ransomware Dataset with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize PCA\n",
    "pca_svm = PCA(n_components = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pca_svm = pca_svm.fit_transform(xTrain)\n",
    "test_pca_svm = pca_svm.transform(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_svm.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call function and feed it PCA features\n",
    "if False:\n",
    "    get_svm(train_pcs_svm, test_pca_svm, yTrain, yTest, features, kernels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. KNN  <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1  KNN for Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(x1, x2, y1, y2, features):\n",
    "    clfKnn = KNeighborsClassifier().fit(x1, y1)\n",
    "    yPredKnn = clfKnn.predict(x2)\n",
    "\n",
    "    log_results = pd.DataFrame({'Actual' : y2, 'Predicted' : yPredKnn})\n",
    "    print(log_results.head(25))\n",
    "    \n",
    "    #distribution of y test\n",
    "    print('y actual : \\n' +  str(y1.value_counts()))\n",
    "    #distribution of y predicted\n",
    "    print('y predicted : \\n' + str(pd.Series(yPredKnn).value_counts()))\n",
    "    \n",
    "    print(\"Score Report : \", metrics.classification_report(y2, yPredKnn))\n",
    "\n",
    "    #print(\"Accuracy : \", metrics.accuracy_score(y2, yPredKnn))\n",
    "    #print(\"Precision : \", metrics.precision_score(y2, yPredKnn))\n",
    "    #print(\"Recall : \", metrics.recall_score(y2, yPredKnn))\n",
    "    #print(\"F1 Score : \", metrics.f1_score(y2, yPredKnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll = prepare_test_sets_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn(xTrainAll, xTestAll, yTrainAll, yTestAll, featuresAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\"> F1 Score for0: 0.99 and for1: 0.23 - so its good at detecting the most popular class out of ransomware or white. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 KNN for Ransomware Dataset with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_gs(x1, x2, y1, y2, features):\n",
    "    clfKnn = KNeighborsClassifier()\n",
    "\n",
    "    params = { 'n_neighbors': [3,5,7,11,9], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "    gClf = GridSearchCV(clfKnn, params, cv = 3)\n",
    "\n",
    "    gClf.fit(x1, y1)\n",
    "    \n",
    "    #analyze the best scores\n",
    "    print(gClf.best_score_, gClf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets(df_ransomware_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_knn_gs(xTrain, xTest, yTrain, yTest, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\"> Best Results for KNN with GS: 0.7314787984159181 {'metric': 'manhattan', 'n_neighbors': 9, 'weights': 'uniform'}</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now use the KNN with the best results as seen from Grid Search\n",
    "newClfKnn = KNeighborsClassifier(metric= 'manhattan', n_neighbors= 9, weights= 'uniform').fit(xTrain, yTrain)\n",
    "yPredKnn = newClfKnn.predict(xTest)\n",
    "\n",
    "log_results = pd.DataFrame({'Actual' : yTest, 'Predicted' : yPredKnn})\n",
    "log_results.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Score Report : \", metrics.classification_report(yTest, yPredKnn))\n",
    "\n",
    "print(\"Accuracy : \", metrics.accuracy_score(yTest, yPredKnn))\n",
    "print(\"Precision : \", metrics.precision_score(yTest, yPredKnn, average = None))\n",
    "print(\"Recall : \", metrics.recall_score(yTest, yPredKnn, average = None))\n",
    "print(\"F1 Score : \", metrics.f1_score(yTest, yPredKnn, average = None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color =\"red\">Well, first step was doing simple KNN for the ransomware dataset: the accuracy was around 0.6 each time. And then I implemented the Grid Search with some given parameters, and got close to 0.8 - therefore I took those prarameters from the Grid Search and implemented KNN with them. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Voting Classifier for ransomware dataset  <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#instantiate the individual algorithms for the ensemble\n",
    "tree = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier(metric= 'manhattan', n_neighbors= 11, weights= 'distance')\n",
    "randomforest = RandomForestClassifier()\n",
    "\n",
    "#create the ensemble\n",
    "vc = VotingClassifier(estimators = [('tree', tree), ('knn', knn), ('randomforest', randomforest)], voting = 'soft')\n",
    "\n",
    "#train the model\n",
    "vc.fit(xTrain, yTrain)\n",
    "\n",
    "yPred_Vc = vc.predict(xTest)\n",
    "\n",
    "print(\"Report Score : \", metrics.classification_report(yTest, yPred_Vc))\n",
    "\n",
    "print(\"Accuracy Score : \", metrics.accuracy_score(yTest, yPred_Vc))\n",
    "print(\"Precision Score : \", metrics.precision_score(yTest, yPred_Vc, average = None))\n",
    "print(\"Recall Score : \", metrics.recall_score(yTest, yPred_Vc, average = None))\n",
    "print(\"F1 Score : \", metrics.f1_score(yTest, yPred_Vc, average = None))\n",
    "    \n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix : \\n\", metrics.confusion_matrix(yTest, yPred_Vc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Neural Networks <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_majority = df_scaled[df_scaled.binary_label==0]\n",
    "df_minority = df_scaled[df_scaled.binary_label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    41413\n",
       "0    23113\n",
       "Name: binary_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We resample the data, since we want the dataset to be balanced to ensure better predictions of ransomware addresses\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                replace=False,    \n",
    "                                 n_samples=23113,     \n",
    "                                 random_state=32) \n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "df_downsampled.binary_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest, features = prepare_test_sets_all(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we're interested in having a NN that works well with unseen data, we are going to work with 3 splits\n",
    "#The three splits are going to be train, validation, and test\n",
    "xVal, xTest, yVal, yTest = train_test_split(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a sequential model, which means that we build the neural network as a sequence, step by step \n",
    "nn1 = Sequential([Dense(32, activation='relu', input_shape=(8,)), \n",
    "                 Dense(32, activation='relu'), Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use stochastic gradient descent as an optimazor\n",
    "#We use binary crossentropy as a loss function since it works best with a classification problem\n",
    "nn1.compile('sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2187516 samples, validate on 546879 samples\n",
      "Epoch 1/100\n",
      "2187516/2187516 [==============================] - 21s 9us/step - loss: 0.0935 - accuracy: 0.9861 - val_loss: 0.0648 - val_accuracy: 0.9866\n",
      "Epoch 2/100\n",
      "2187516/2187516 [==============================] - 21s 9us/step - loss: 0.0642 - accuracy: 0.9867 - val_loss: 0.0635 - val_accuracy: 0.9868\n",
      "Epoch 3/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0633 - accuracy: 0.9868 - val_loss: 0.0628 - val_accuracy: 0.9868\n",
      "Epoch 4/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0627 - accuracy: 0.9868 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
      "Epoch 5/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0623 - accuracy: 0.9869 - val_loss: 0.0620 - val_accuracy: 0.9869\n",
      "Epoch 6/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.0617 - val_accuracy: 0.9870\n",
      "Epoch 7/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9870\n",
      "Epoch 8/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0614 - accuracy: 0.9870 - val_loss: 0.0612 - val_accuracy: 0.9870\n",
      "Epoch 9/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0612 - accuracy: 0.9870 - val_loss: 0.0611 - val_accuracy: 0.9870\n",
      "Epoch 10/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0611 - accuracy: 0.9870 - val_loss: 0.0609 - val_accuracy: 0.9870\n",
      "Epoch 11/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0609 - accuracy: 0.9870 - val_loss: 0.0608 - val_accuracy: 0.9870\n",
      "Epoch 12/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0608 - accuracy: 0.9870 - val_loss: 0.0607 - val_accuracy: 0.9870\n",
      "Epoch 13/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0607 - accuracy: 0.9870 - val_loss: 0.0606 - val_accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0606 - accuracy: 0.9870 - val_loss: 0.0605 - val_accuracy: 0.9871\n",
      "Epoch 15/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0605 - accuracy: 0.9870 - val_loss: 0.0604 - val_accuracy: 0.9871\n",
      "Epoch 16/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0604 - accuracy: 0.9870 - val_loss: 0.0603 - val_accuracy: 0.9871\n",
      "Epoch 17/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0603 - accuracy: 0.9870 - val_loss: 0.0602 - val_accuracy: 0.9871\n",
      "Epoch 18/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0603 - accuracy: 0.9870 - val_loss: 0.0602 - val_accuracy: 0.9871\n",
      "Epoch 19/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0602 - accuracy: 0.9870 - val_loss: 0.0601 - val_accuracy: 0.9871\n",
      "Epoch 20/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0602 - accuracy: 0.9870 - val_loss: 0.0601 - val_accuracy: 0.9871\n",
      "Epoch 21/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0601 - accuracy: 0.9870 - val_loss: 0.0600 - val_accuracy: 0.9871\n",
      "Epoch 22/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0600 - accuracy: 0.9870 - val_loss: 0.0599 - val_accuracy: 0.9871\n",
      "Epoch 23/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0600 - accuracy: 0.9870 - val_loss: 0.0599 - val_accuracy: 0.9871\n",
      "Epoch 24/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0599 - accuracy: 0.9871 - val_loss: 0.0598 - val_accuracy: 0.9871\n",
      "Epoch 25/100\n",
      "2187516/2187516 [==============================] - 24s 11us/step - loss: 0.0599 - accuracy: 0.9871 - val_loss: 0.0598 - val_accuracy: 0.9871\n",
      "Epoch 26/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0598 - accuracy: 0.9870 - val_loss: 0.0597 - val_accuracy: 0.9871\n",
      "Epoch 27/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0598 - accuracy: 0.9871 - val_loss: 0.0597 - val_accuracy: 0.9871\n",
      "Epoch 28/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0597 - accuracy: 0.9871 - val_loss: 0.0596 - val_accuracy: 0.9871\n",
      "Epoch 29/100\n",
      "2187516/2187516 [==============================] - 22s 10us/step - loss: 0.0597 - accuracy: 0.9871 - val_loss: 0.0596 - val_accuracy: 0.9871\n",
      "Epoch 30/100\n",
      "2187516/2187516 [==============================] - 19s 8us/step - loss: 0.0596 - accuracy: 0.9871 - val_loss: 0.0595 - val_accuracy: 0.9871\n",
      "Epoch 31/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0596 - accuracy: 0.9871 - val_loss: 0.0595 - val_accuracy: 0.9872\n",
      "Epoch 32/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0595 - accuracy: 0.9871 - val_loss: 0.0594 - val_accuracy: 0.9872\n",
      "Epoch 33/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0595 - accuracy: 0.9871 - val_loss: 0.0594 - val_accuracy: 0.9872\n",
      "Epoch 34/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0594 - accuracy: 0.9871 - val_loss: 0.0593 - val_accuracy: 0.9872\n",
      "Epoch 35/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0594 - accuracy: 0.9871 - val_loss: 0.0593 - val_accuracy: 0.9872\n",
      "Epoch 36/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0593 - accuracy: 0.9871 - val_loss: 0.0592 - val_accuracy: 0.9872\n",
      "Epoch 37/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0593 - accuracy: 0.9871 - val_loss: 0.0592 - val_accuracy: 0.9872\n",
      "Epoch 38/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0592 - accuracy: 0.9871 - val_loss: 0.0591 - val_accuracy: 0.9872\n",
      "Epoch 39/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0592 - accuracy: 0.9871 - val_loss: 0.0591 - val_accuracy: 0.9872\n",
      "Epoch 40/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0592 - accuracy: 0.9871 - val_loss: 0.0591 - val_accuracy: 0.9872\n",
      "Epoch 41/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0591 - accuracy: 0.9871 - val_loss: 0.0590 - val_accuracy: 0.9872\n",
      "Epoch 42/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0591 - accuracy: 0.9872 - val_loss: 0.0590 - val_accuracy: 0.9872\n",
      "Epoch 43/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0590 - accuracy: 0.9872 - val_loss: 0.0589 - val_accuracy: 0.9872\n",
      "Epoch 44/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0590 - accuracy: 0.9872 - val_loss: 0.0589 - val_accuracy: 0.9872\n",
      "Epoch 45/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0589 - accuracy: 0.9872 - val_loss: 0.0588 - val_accuracy: 0.9872\n",
      "Epoch 46/100\n",
      "2187516/2187516 [==============================] - 23s 11us/step - loss: 0.0589 - accuracy: 0.9872 - val_loss: 0.0588 - val_accuracy: 0.9872\n",
      "Epoch 47/100\n",
      "2187516/2187516 [==============================] - 21s 9us/step - loss: 0.0588 - accuracy: 0.9872 - val_loss: 0.0587 - val_accuracy: 0.9872\n",
      "Epoch 48/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0588 - accuracy: 0.9872 - val_loss: 0.0587 - val_accuracy: 0.9872\n",
      "Epoch 49/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0587 - accuracy: 0.9872 - val_loss: 0.0586 - val_accuracy: 0.9873\n",
      "Epoch 50/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0587 - accuracy: 0.9872 - val_loss: 0.0586 - val_accuracy: 0.9873\n",
      "Epoch 51/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0587 - accuracy: 0.9872 - val_loss: 0.0586 - val_accuracy: 0.9873\n",
      "Epoch 52/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0586 - accuracy: 0.9872 - val_loss: 0.0585 - val_accuracy: 0.9873\n",
      "Epoch 53/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0586 - accuracy: 0.9872 - val_loss: 0.0585 - val_accuracy: 0.9873\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0585 - accuracy: 0.9872 - val_loss: 0.0584 - val_accuracy: 0.9873\n",
      "Epoch 55/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0585 - accuracy: 0.9872 - val_loss: 0.0584 - val_accuracy: 0.9873\n",
      "Epoch 56/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0584 - accuracy: 0.9873 - val_loss: 0.0583 - val_accuracy: 0.9873\n",
      "Epoch 57/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0584 - accuracy: 0.9873 - val_loss: 0.0583 - val_accuracy: 0.9873\n",
      "Epoch 58/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0584 - accuracy: 0.9873 - val_loss: 0.0583 - val_accuracy: 0.9874\n",
      "Epoch 59/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0583 - accuracy: 0.9873 - val_loss: 0.0582 - val_accuracy: 0.9873\n",
      "Epoch 60/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0583 - accuracy: 0.9873 - val_loss: 0.0582 - val_accuracy: 0.9874\n",
      "Epoch 61/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0582 - accuracy: 0.9873 - val_loss: 0.0581 - val_accuracy: 0.9874\n",
      "Epoch 62/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0582 - accuracy: 0.9873 - val_loss: 0.0581 - val_accuracy: 0.9874\n",
      "Epoch 63/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0581 - accuracy: 0.9873 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 64/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0581 - accuracy: 0.9873 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0581 - accuracy: 0.9873 - val_loss: 0.0580 - val_accuracy: 0.9874\n",
      "Epoch 66/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.0579 - val_accuracy: 0.9874\n",
      "Epoch 67/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.0579 - val_accuracy: 0.9874\n",
      "Epoch 68/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 69/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0579 - accuracy: 0.9873 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 70/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0579 - accuracy: 0.9873 - val_loss: 0.0578 - val_accuracy: 0.9874\n",
      "Epoch 71/100\n",
      "2187516/2187516 [==============================] - 22s 10us/step - loss: 0.0579 - accuracy: 0.9873 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 72/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0578 - accuracy: 0.9873 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 73/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0578 - accuracy: 0.9873 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 74/100\n",
      "2187516/2187516 [==============================] - 20s 9us/step - loss: 0.0578 - accuracy: 0.9873 - val_loss: 0.0577 - val_accuracy: 0.9874\n",
      "Epoch 75/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0577 - accuracy: 0.9873 - val_loss: 0.0576 - val_accuracy: 0.9874\n",
      "Epoch 76/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0577 - accuracy: 0.9874 - val_loss: 0.0576 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0577 - accuracy: 0.9874 - val_loss: 0.0576 - val_accuracy: 0.9874\n",
      "Epoch 78/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9874\n",
      "Epoch 79/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9874\n",
      "Epoch 80/100\n",
      "2187516/2187516 [==============================] - 21s 9us/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9874\n",
      "Epoch 81/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0576 - accuracy: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9875\n",
      "Epoch 82/100\n",
      "2187516/2187516 [==============================] - 16s 7us/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.0574 - val_accuracy: 0.9875\n",
      "Epoch 83/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.0574 - val_accuracy: 0.9875\n",
      "Epoch 84/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.0574 - val_accuracy: 0.9875\n",
      "Epoch 85/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0575 - accuracy: 0.9874 - val_loss: 0.0574 - val_accuracy: 0.9875\n",
      "Epoch 86/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0574 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
      "Epoch 87/100\n",
      "2187516/2187516 [==============================] - 15s 7us/step - loss: 0.0574 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
      "Epoch 88/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0574 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
      "Epoch 89/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0574 - accuracy: 0.9874 - val_loss: 0.0573 - val_accuracy: 0.9875\n",
      "Epoch 90/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0573 - accuracy: 0.9874 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "2187516/2187516 [==============================] - 19s 9us/step - loss: 0.0573 - accuracy: 0.9874 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0573 - accuracy: 0.9875 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 93/100\n",
      "2187516/2187516 [==============================] - 18s 8us/step - loss: 0.0573 - accuracy: 0.9874 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 94/100\n",
      "2187516/2187516 [==============================] - 23s 10us/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0572 - val_accuracy: 0.9875\n",
      "Epoch 95/100\n",
      "2187516/2187516 [==============================] - 32s 14us/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0571 - val_accuracy: 0.9875\n",
      "Epoch 96/100\n",
      "2187516/2187516 [==============================] - 16s 8us/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0571 - val_accuracy: 0.9875\n",
      "Epoch 97/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0571 - val_accuracy: 0.9875\n",
      "Epoch 98/100\n",
      "2187516/2187516 [==============================] - 21s 9us/step - loss: 0.0572 - accuracy: 0.9875 - val_loss: 0.0571 - val_accuracy: 0.9875\n",
      "Epoch 99/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0571 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9875\n",
      "Epoch 100/100\n",
      "2187516/2187516 [==============================] - 17s 8us/step - loss: 0.0571 - accuracy: 0.9875 - val_loss: 0.0570 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "pred1 = nn1.fit(xTrain, yTrain, batch_size=924, epochs=100, validation_data=(xVal, yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182294/182294 [==============================] - 7s 38us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9877176284790039"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn1.evaluate(xTest, yTest)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"purple\">  Note: if we try changing the batches we might achieve better results </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We want both curves to go downwards, if the orange is increasing it's overfitting.\n",
    "#We want the organge curve to have a loss function that is as similar to the orange curve as possible.\n",
    "plt.plot(pred1.history['loss'])\n",
    "plt.plot(pred1.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pred1.history['accuracy'])\n",
    "plt.plot(pred1.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We make a second model that tries \n",
    "nn2 = Sequential([\n",
    "    Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(8,)),\n",
    "    Dropout(0.3),\n",
    "    Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(500, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2187516 samples, validate on 546879 samples\n",
      "Epoch 1/100\n",
      " 538692/2187516 [======>.......................] - ETA: 3:15 - loss: 5.3752 - accuracy: 0.9758"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-59f525e3f90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m924\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred2 = nn2.fit(xTrain, yTrain, batch_size=924, epochs=100, validation_data=(xVal, yVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2.evaluate(xTest, yTest)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want training and validation results to be similar\n",
    "plt.plot(pred2.history['loss'])\n",
    "plt.plot(pred2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.ylim(top=1.2, bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want the orange line to not stay under the blue line. \n",
    "#We improved the model a bit because we can rely on good predictions\n",
    "plt.plot(pred2.history['accuracy'])\n",
    "plt.plot(pred2.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"red\"> Conclusion: we can use regularization for ensuring that the model does not overfit. This is achieved with random dropout. </font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.2_DecisionTreesPrecisionMeasures_student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
